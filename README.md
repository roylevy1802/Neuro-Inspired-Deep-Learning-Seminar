**Abstract:**

How can machines learn as efficiently as humans and animals?

How can we build machine architectures capable of complex reasoning, planning and problem solving, common-sense, understanding of the physical world, and capable of autonomous intelligence? 

What does nature’s hundred-million-year optimization algorithm have to teach us about intelligence? More fundamentally, what is intelligence?

This seminar aims to explore the nature of human intelligence and implement it in intelligent machine architectures, through knowledge of the complex operation of the human and animal brain, then combined with deep learning research.
We will first explore foundations in neuroscience, cognitive science and brain evolution that will guide us for the rest of the seminar, understanding the major mechanisms behind the human and animal brain, as well as their operation.

Then, we will research reward mechanisms and reinforcement learning in machine learning, a crucial foundation for building the higher, subsequent forms of machine intelligence mechanisms.

Next, this seminar will research implementations of internal simulation and world modeling in deep learning architectures, leading to a comprehensive hierarchical non-generative architecture capable of representing multiple futures in a non-deterministic manner, accounting for uncertainty and internal chaos in the world. We will discuss the limitations of current generative models (i.e., LLMs), how to solve them, as well as the bigger-picture place of language in AI models.

Lastly, we will explore a new form of intelligence in machine architectures, capable of theory-of-mind as well as thinking about one’s own thinking, understanding the notion of goal and the whys, as well as learning skills from observation. This mechanism is known as mentalization.
